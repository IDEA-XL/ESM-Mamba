{
    "aligner_config": {
      "cls": "MlpProjector",
      "model_type": "aligner",
      "params": {
        "depth": 2,
        "input_dim": 1536,
        "n_embed": 1536,
        "projector_type": "mlp_gelu"
      }
    },
    "gen_aligner_config": {
      "cls": "MlpProjector",
      "model_type": "gen_aligner",
      "params": {
        "depth": 2,
        "input_dim": 8,
        "n_embed": 1536,
        "projector_type": "mlp_gelu"
      }
    },
    "gen_head_config": {
      "cls": "structure_head",
      "model_type": "gen_head",
      "params": {
        "structure_token_embed": 1536,
        "structure_token_size": 4096,
        "n_embed": 1536
      }
    },
    "gen_structure_config": {
      "cls": "StructureTokenEncoder",
      "model_type": "gen_structure",
      "params": {
        "structure_token_size": 4096,
        "n_embed": 8
      }
    },
    "language_config": {
        "activation_function": "gelu_new",
        "architectures": [
            "ProGenForCausalLM"
        ],
        "attn_pdrop": 0.0,
        "bos_token_id": 1,
        "embd_pdrop": 0.0,
        "eos_token_id": 2,
        "gradient_checkpointing": false,
        "initializer_range": 0.02,
        "layer_norm_epsilon": 1e-05,
        "model_type": "progen",
        "n_embd": 1536,
        "n_head": 16,
        "n_layer": 27,
        "n_positions": 1024,
        "rotary_dim": 48,
        "summary_activation": null,
        "summary_first_dropout": 0.1,
        "summary_proj_to_labels": true,
        "summary_type": "cls_index",
        "summary_use_proj": true,
        "tokenizer_class": "GPT2Tokenizer",
        "task_specific_params": {
            "text-generation": {
            "do_sample": true,
            "temperature": 1.0,
            "max_length": 50
            }
        },
        "torch_dtype": "float32",
        "use_cache": false,
        "vocab_size": 32
    },
    "model_type": "multi_modality",
    "torch_dtype": "bfloat16",
    "transformers_version": "4.38.2",
    "structure_config": {
      "cls": "CLIPVisionTower", 
      "model_type": "structure",
      "params": {
        "image_size": 384,
        "model_name": "siglip_large_patch16_384",
        "select_feature": "same",
        "select_layer": -1
      }
    }
  }